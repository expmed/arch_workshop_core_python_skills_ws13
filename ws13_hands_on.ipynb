{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "746b9425-7aaf-4d01-add3-a465512c2190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e6cc9-e7c4-4ac1-8c8c-7d52ad80ee4a",
   "metadata": {},
   "source": [
    "## I) Loading Data Into Pandas DataFrames and Inspecting It"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5365970",
   "metadata": {},
   "source": [
    "To load data into a Pandas Dataframe, you can use the `pandas.read_*` suite of functions. Common examples are.\n",
    "- `pandas.read_csv()` to read from a comma separated values file\n",
    "- `pandas.read_sql()` to read directly from a SQL database (either table by name or SQL query constructed as a string)\n",
    "- `pandas.read_table()` to read from a more general delimited tabular file (could be comma, tab, space, `'|'`, or otherwise delimited)\n",
    "- `pandas.read_json()` to read from a .json file, but pandas will expect the JSON data to have a particular structure\n",
    "- `pandas.read_parquet()` to read from an Apache Parquet columnar store file\n",
    "\n",
    "Below, we use `pandas.read_parquet()` to read from an [Apache Parquet](https://parquet.apache.org/) data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3764a6e-69f5-4107-85f5-a2e6c80868ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: loading the synthetic patients file simulated for the state of Massachusetts\n",
    "patients_ma = pd.read_parquet('https://github.com/expmed/arch_workshop_core_python_skills_ws13/raw/refs/heads/main/data/output_ma_small/parquet/patients.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf766787",
   "metadata": {},
   "source": [
    "To inspect the data in a DataFrame visually, we can just write the name of our dataframe and evaluate it. Or if we want a shorter summary, we can use the `DataFrame.head()` method to only show the top n rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a8f5f-fc93-4b18-b7c2-0bb1a53c6958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 5 rows\n",
    "patients_ma.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4186f188",
   "metadata": {},
   "source": [
    "We can also display the names of all columns/variables in the DataFrame, and their types, by accessing the `.columns` and `.dtypes` attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39f7d3-2318-4714-a2bf-2e59cd889d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the columns in the DataFrame\n",
    "patients_ma.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10182c76-37ae-4fbf-8759-577883140523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the columns and their datatypes\n",
    "patients_ma.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0218e7be",
   "metadata": {},
   "source": [
    "We can also access the data in a particular column (or set of columns) by providing the column name(s) in square brackets\n",
    "- When we access a single column, the type of object we get back is known as a Pandas `Series`. Think of this like a column of data\n",
    "- When we access multiple columns of data using a list of names, such as `['Column1', 'Column2', 'Column3', ...]` we get back another `DataFrame`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ae9f45-3bb3-410b-a5c2-151855fc6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the data in a particular column\n",
    "patients_ma['FIRST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e7f9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(patients_ma['FIRST'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69366d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing the data in a set of columns\n",
    "patients_ma[['FIRST', 'MIDDLE', 'LAST']]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d605ac21",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(patients_ma[['FIRST', 'MIDDLE', 'LAST']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9131e2b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# columns can also be accesssed using the dot notation like with attributes\n",
    "patients_ma.FIRST"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db6142d-fcc4-4406-a2dd-ea6c33f8534e",
   "metadata": {},
   "source": [
    "## II) Basic Data Manipulation with DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81eb33b5",
   "metadata": {},
   "source": [
    "### II.a) Stitching (Concatenating) Data Together\n",
    "- In Section I, we loaded in patient demographics data for the state of Massachussets\n",
    "- We also have simulated data for the states of Hawaii, Texas, and Washington\n",
    "- If we want to work with a single dataset of all patients in a single DataFrame, we can use the building `pandas.concat()` function\n",
    "- `pandas.concat()` can take in a bracketed list of dataframes, such as `[df1, df2, df3,...]` and concatenate them together row-wise into a single table\n",
    "- The only requirement (or recommendation) is that all dataframes to be appended in this way have the same schema (names, types, and number of columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d055596c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for loading data from the Github repository\n",
    "def load_data_from_github(filename):\n",
    "    url = os.path.join('https://github.com/expmed/arch_workshop_data_wrangling1_ws9/raw/refs/heads/main/data', filename)\n",
    "    return pd.read_parquet(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a2d1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the patients data for the other states\n",
    "patients_hi = load_data_from_github('output_hi_small/parquet/patients.parquet')\n",
    "patients_wa = load_data_from_github('output_wa_small/parquet/patients.parquet')\n",
    "patients_tx = load_data_from_github('output_tx_small/parquet/patients.parquet')\n",
    "\n",
    "# now combine the four DataFrames into one\n",
    "patients = pd.concat([patients_ma, patients_hi, patients_wa, patients_tx], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "030ceeea-7047-4e9d-ae69-fdcc6797981f",
   "metadata": {},
   "source": [
    "### II.b) Counting\n",
    "\n",
    "Suppose we want to count the number of patients by GENDER in our dataset\n",
    "We can do so in two different ways\n",
    "1. We can use the `Series.value_counts()` to count the distinct values in a given column/`Series`\n",
    "2. We can use the `DataFrame.groupby()` method to group rows by a particular column (or set of columns) and then apply different aggregations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3798be36-b206-49f9-86e8-760ec51f25da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of male and female patients\n",
    "patients['GENDER'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed7e05cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative approach using the groupby method, which takes in a column name, and then we apply an aggregate function\n",
    "patients.groupby('GENDER').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdbcc741-9332-4e13-9518-5f3b6ecc970c",
   "metadata": {},
   "source": [
    "### II.c) Cross tabulations/Contingency Tables\n",
    "\n",
    "Suppose now that we want to count the number of patients by both `GENDER` and `RACE`. We can do so in two different ways\n",
    "1. Using the `pandas.crosstab()` method, which takes in two different columns/`Series` to be cross-tabulated\n",
    "2. Using the `DataFrame.pivot_table()` method, which takes in the column names as either `index=` or `columns=` arguments, and an aggregate function\n",
    "\n",
    "`pandas.crosstab()` is arguably the cleaner/nicer interface, since it automatically fills NAs and converts to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81f3a716-06ad-4062-bad4-4d36f813e6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# count patients by gender and race\n",
    "pd.crosstab(patients['GENDER'], patients['RACE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26a2ba1-623f-47ec-9921-ad86ec181423",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative method using df.pivot_table(), but need to provide an aggregate function\n",
    "patients.pivot_table(index='GENDER', columns='RACE', aggfunc='size')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a30e600",
   "metadata": {},
   "source": [
    "However, `DataFrame.pivot_table()` is more versatile, since we can also give the name of a column of values to be aggregated \\\n",
    "and we can do different kinds of aggregations (e.g., averaging, summing, min, max, etc.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac6701b9-e16b-4121-bc91-f78b64c31be3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the average healthcare expenses by gender and race\n",
    "patients.pivot_table(values='HEALTHCARE_EXPENSES', index='GENDER', columns='RACE', aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c129fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# computing the total healthcare expenses by gender and race\n",
    "patients.pivot_table(values='HEALTHCARE_EXPENSES', index='GENDER', columns='RACE', aggfunc='sum')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaf8103d-ba79-40e1-a772-351679bcc763",
   "metadata": {},
   "source": [
    "### II.d) Descriptive Statistics\n",
    "If we want to compoute descriptive statistics for particular variables/columns, there are a variety of built-in methods on `Series` as well as built in to the NumPy package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19367455-0c3c-4826-872e-244475830988",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average healthcare expenses\n",
    "patients['HEALTHCARE_EXPENSES'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7464dd82-9cee-4810-87ff-90e428cefac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing a larger suite of descriptive statistics\n",
    "patients['HEALTHCARE_EXPENSES'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a593a5a-acfe-48dd-86c2-96b686636de7",
   "metadata": {},
   "source": [
    "### II.e) Descriptive Statistics with Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cd82ac-e0a8-449a-aa6f-487604b5b91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the average healthcare expenses\n",
    "np.mean(patients['HEALTHCARE_EXPENSES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84e47b8-5733-49e3-9a7c-b3bccbba6bcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the standard deviation of healthcare expenses\n",
    "np.std(patients['HEALTHCARE_EXPENSES'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ed04e0-c52b-4185-a596-f1f998cc7253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also call methods directly on columns/pandas series\n",
    "patients['HEALTHCARE_EXPENSES'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67611a8a-3411-490c-b899-921e7d95a4cb",
   "metadata": {},
   "source": [
    "Quick Question: Why did Numpy's std() give a different (smaller) value for the standard deviation than Pandas?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6515275b-13db-4fa0-8ccd-84d9345a2f96",
   "metadata": {},
   "source": [
    "### II.f) Filtering DataFrames\n",
    "If we want to extract data for specific subsets of records based on the values assigned to certain variables, we can use logical indexing\n",
    "- If we want to extract all records with a certain value in a column, we can write `df[df['column_name'] == value]`\n",
    "- We can use typical boolean operators for filtering such as `>`, `<`, `>=`, `<=`, etc.\n",
    "If we want to chain logical filters we use the bitwise operators:\n",
    "- `&` for logical `AND`\n",
    "- `|` for logical `OR`\n",
    "We need to be careful about order of operations here, since `|` and `&` have higher precedence than `==`, `<`, etc. in Python\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24d4b15a-3bd6-401b-a662-d207e894a762",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting only patients who are female\n",
    "females = patients[patients['GENDER'] == 'F'] # or patients.query('GENDER == \"F\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc02a924-3090-4380-a7c7-5a99a6e81526",
   "metadata": {},
   "outputs": [],
   "source": [
    "females"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6acae92-dfa9-470e-a350-670b7cd83025",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get patients born after 1990\n",
    "patients[patients['BIRTHDATE'] >= '1990-01-01']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41cdd21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get patients who are female AND born after 1990\n",
    "patients[\n",
    "    (patients['BIRTHDATE'] >= '1990-01-01') &\n",
    "    (patients['GENDER'] == 'F')\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fda921c",
   "metadata": {},
   "source": [
    "Pandas also supports a `DataFrame.query()` method that has a somewhat more succinct, if not slightly more confusing syntax for filtering purposees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c51bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same as the example above, but using the query method\n",
    "patients.query('BIRTHDATE >= \"1990-01-01\" and GENDER == \"F\"')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6dccd0a-90cf-443a-ae80-06c94f65342b",
   "metadata": {},
   "source": [
    "### II.g) Sorting\n",
    "We can also sort the records/rows in a dataframe by a particular column or set of columns using `DataFrame.sort_values()`\n",
    "- This method takes in an optional keyword argument `ascending=True|False` which can be used for ascending/decreasing order of the sort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fc90a6-1f38-4ed5-8062-2817e1a612e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get patients born after 1990, and sort by birthdate\n",
    "patients[patients['BIRTHDATE'] >= '1990-01-01'].sort_values(by='BIRTHDATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c0e6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# do the same, but sort in decreasing order by birthdate\n",
    "patients.query('BIRTHDATE >= \"1990-01-01\"').sort_values(by='BIRTHDATE', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa5f7d62-cc30-46b3-9077-066e3b1c1a64",
   "metadata": {},
   "source": [
    "### II.h) Assigning New Columns/Variables\n",
    "If we want to assign a new column/variable to the dataframe, we can do this by either\n",
    "- Writing `df[<column_name>] = <values>`, which changes/modifies the DataFrame in place\n",
    "- Using the `DataFrame.assign()` method, which by default returns a copy of the original dataframe with the new column added\n",
    "- `DataFrame.assign()` is quite a bit more flexible, easier to read, and easier to reason about (once you get comfortable with it), \\\n",
    "and it supports a higher order functional approach to specifying the values that get assigned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b327216-c7b4-4d31-bec7-4d5c51839203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assign a full name column\n",
    "patients['FULLNAME'] = patients['FIRST'] + ' ' + patients['MIDDLE'] + ' ' + patients['LAST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b4d64a-1266-4942-85a6-fcde120c61ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['FULLNAME']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f69c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# same as above, but using the asssign() method\n",
    "patients.drop(columns=['FULLNAME'], inplace=True, errors='ignore') # drop the column if it exists\n",
    "patients.assign(\n",
    "    FULLNAME=lambda x: x['FIRST'] + ' ' + x['MIDDLE'] + ' ' + x['LAST']\n",
    ")[['FULLNAME', 'FIRST', 'MIDDLE', 'LAST']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb4d8c8d",
   "metadata": {},
   "source": [
    "### II.i) Filling in Missing Values (NaNs)\n",
    "We can also use Pandas to work with missing data, filtering rows/columns with missing data, and imputing missing values \\\n",
    "We can inspect which values in a DataFrame are missing by calling `DataFrame.isnull()` \\\n",
    "If we want to fill in missing values, we can use `DataFrame.fillna()` or `Series.fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf035d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients.isnull()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d1a63ef",
   "metadata": {},
   "source": [
    "Here we simulate a 10% missing values rate in the HEALTHCARE_EXPENSES column by randomly overwriting 10% of the values with `np.nan`\n",
    "- `np.nan` is a built in special floating point sigil value provided by numpy and used to signify a missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4913f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate some missing values in the healthcare expenses column\n",
    "# NOTE: DataFrame.loc[] is used to access a group of rows and columns by labels or a logical array\n",
    "# NOTE: DataFrame.sample() is used to randomly sample rows from the DataFrame\n",
    "# NOTE: DataFrame.index is used to access the index (row labels) of the DataFrame\n",
    "np.random.seed(42) # for reproducibility\n",
    "patients.loc[patients.sample(frac=0.1).index, 'HEALTHCARE_EXPENSES'] = np.nan\n",
    "patients['HEALTHCARE_EXPENSES'].isnull().sum() / len(patients) * 100 # percentage of missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84a2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now if we wanted to fill in the missing values with the mean\n",
    "patients['HEALTHCARE_EXPENSES'].fillna(patients['HEALTHCARE_EXPENSES'].mean()).isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beefe352",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['HEALTHCARE_EXPENSES'].fillna(patients['HEALTHCARE_EXPENSES'].mean()).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd1171b",
   "metadata": {},
   "outputs": [],
   "source": [
    "patients['HEALTHCARE_EXPENSES'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cbc69ec",
   "metadata": {},
   "source": [
    "### II.j) Handling DateTime Variables\n",
    "By default, most data representing dates, times, and datetimes will be loaded by Pandas as plain text \\\n",
    "In order to treat these as actual date objects and perform calculations, we need to explicitly convert the columns \\\n",
    "to a `datetimeN` datatype. In pandas, we can use the `pd.to_datetime()` function to convert a series to a datetime type.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16947580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by default, the BIRTHDATE column is of type object (plaintext), but we can convert it to datetime\n",
    "patients['BIRTHDATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f991c36f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.to_datetime(patients['BIRTHDATE'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26436eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can also get todays date using pandas\n",
    "pd.to_datetime('today')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb43f316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can easily do computations, such as the differenced between to dates\n",
    "# what we get back from the computation is a series of timedelta objects\n",
    "pd.to_datetime('today') - pd.to_datetime(patients['BIRTHDATE'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e53697-508d-4c36-8d53-b556cc4cb4f3",
   "metadata": {},
   "source": [
    "## III) Visualizing Distributions with Pandas, Matplotlib, and Seaborn\n",
    "The Matplotlib and Seaborn packages support a wide array of built-in chart types for creating figures/visualizations. \\\n",
    "Here we will just briefly look at some of the functionality. Pandas also has a number of built-in methods that can be \\\n",
    "called directly on `DataFrames` and `Series`, which use Matplotlib under the hood.\n",
    "\n",
    "- Above, we imported the `pyplot` submodule from `matplotlib` with `from matplotlib import pyplot as plt`, so that we can just write `plt.<some_method>()` to use plotting functionality\n",
    "- Similarly, we aliased `seaborn` as `import seaborn as sns`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75f1a83-5229-43f6-bcd3-520c9250740f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the distribution of income as a histogram\n",
    "fig, ax = plt.subplots(dpi=150)\n",
    "patients['INCOME'].hist(bins=20, ax=ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3929e592-66e8-4b04-8e85-c10bb81c241f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative using matplotlib directly\n",
    "plt.hist(patients['INCOME'], bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf95e52-da49-413b-8bcf-3582537ee43d",
   "metadata": {},
   "source": [
    "### III.a) Grouped Histograms\n",
    "When creating histograms with `DataFrame.hist()`, we can also generate grouped histograms by providing a column name in the `by=` keyword argument"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f5fdb11-9d79-4da9-8fd4-cc9a7e54ee98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plotting the distributions of healthcare expenses by gender\n",
    "fig, ax = plt.subplots(1, 2, dpi=150)\n",
    "patients.hist('HEALTHCARE_EXPENSES', by='GENDER', bins=20, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fe6fb51-b8d9-4dfb-bc12-0307acb243e1",
   "metadata": {},
   "source": [
    "### III.b) Box Plots and Violin Plots with Seaborn\n",
    "The Seaborn package builds on top of Matplotlib with a nice set of customizable aesthetic defaults, and a somewhat extended suite of statistical charts compared to what is offered in vanilla Matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c521b622-d976-47cd-8314-06214cc98e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative approaches to visualizing distributions with seaborn\n",
    "sns.boxplot(patients, x='GENDER', y='HEALTHCARE_EXPENSES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf1b5d5-1e86-4296-81d6-cee2306cf817",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(patients, x='RACE', y='HEALTHCARE_EXPENSES', hue='GENDER')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b459826-a7aa-4fae-af94-cbaa903d4167",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(patients, x='GENDER', y='HEALTHCARE_EXPENSES')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff14e6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.violinplot(patients, x='RACE', hue='GENDER', y='HEALTHCARE_EXPENSES')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87644a0-e9bf-4fbe-adf5-d2766def64b3",
   "metadata": {},
   "source": [
    "## IV) Quick Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f585516-99cc-4416-8e13-3d1e7a176768",
   "metadata": {},
   "source": [
    "### 1. What is the median income of patients born after January 1st 1995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde7730c-4d9c-4145-8764-b93bcffd356a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and run your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730eb169-332d-450f-ba86-3043113bd5ef",
   "metadata": {},
   "source": [
    "### 2. Count the number of patients in each COUNTY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca64c09-a4b1-4a3f-995b-3bd33cddb393",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and run your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37ebb31-fa82-4f31-9de1-68fb14d0527f",
   "metadata": {},
   "source": [
    "### 3. What is the mean age (in years) of all patients?\n",
    "<details>\n",
    "    <summary>Hint 1</summary>\n",
    "    <h4>You can convert BIRTHDATE to the datetime data type using <code>pd.to_datetime()</code></h4>\n",
    "</details>\n",
    "<details>\n",
    "    <summary>Hint 2</summary>\n",
    "    <h4>You can get today's date with <code>pd.to_datetime(\"today\")</code></h4>\n",
    "</details>\n",
    "<details>\n",
    "    <summary>Hint 3</summary>\n",
    "    <h4>You can use the <code>.dt.days</code> method on a datetime column/series or datetime value to get the value of the date(s) expressed in days</h4>\n",
    "</details>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d13a342-fa87-4376-8df5-66cd91b1f111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and run your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ecd978-62f0-4e33-bb80-e4a08a1bfa99",
   "metadata": {},
   "source": [
    "### 4. Count the number of patients of each RACE who are over 60\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    <h4>If you didn't save the AGE that we computed in the last exercise to a column/variable, do that first</h4>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a440f69-04c6-4383-927d-0fd25da6876b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and run your solution here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce27b8f-786c-43b8-bd72-aba80df35cc5",
   "metadata": {},
   "source": [
    "### 5. Generate a grouped histogram of income distributions by 10 year AGE cohorts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc8478dd-e24b-4129-9946-a133c798fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an AGE_BIN column\n",
    "patients['AGE_BIN'] = pd.cut(patients['AGE'], np.arange(0, 120, 10), include_lowest=True)\n",
    "\n",
    "fig, ax = plt.subplots(3, 4, dpi=150, figsize=(8, 6))\n",
    "\n",
    "# Flatten the axes array\n",
    "ax = ax.flatten()\n",
    "\n",
    "# Count the number of unique AGE_BINs\n",
    "num_groups = patients['AGE_BIN'].nunique()\n",
    "\n",
    "# insert your plotting code here, passing in ax=ax[:num_groups] as a keyword argument to the correct plot function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b47b0de9-570d-4529-8024-81696c53e73f",
   "metadata": {},
   "source": [
    "### 6. Plot INCOME vs AGE for all patients\n",
    "<details>\n",
    "    <summary>Hint</summary>\n",
    "    <p>The pandas documentation for <a href=\"https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.plot.scatter.html\">DataFrame.plot.scatter</a> might prove useful</p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8238c950-2b96-407d-9862-be0062ef45c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write and run your solution here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
