{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "815794dd",
   "metadata": {},
   "source": [
    "# Tools-driven Mock Case Study of Type 2 Diabetes\n",
    "\n",
    "In this module, we will:\n",
    "1. Load and explore synthetic EHR data generated using Synthea.\n",
    "2. Identify patients diagnosed with Type 2 Diabetes using SNOMED CT codes.\n",
    "3. Analyze Hemoglobin A1C (HbA1c) levels in diabetic and non-diabetic patients.\n",
    "4. Visualize data distributions and perform statistical testing.\n",
    "5. Discuss findings and explore possible extensions.\n",
    "6. Along the way, learn core python packages and tools including Pandas, Numpy, Scipy, Matplotlib, and Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a8fd37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import scipy as sp\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f1e6cc9-e7c4-4ac1-8c8c-7d52ad80ee4a",
   "metadata": {},
   "source": [
    "## I) Loading Relevant Data Into Pandas DataFrames, Stitching, and Inspecting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5365970",
   "metadata": {},
   "source": [
    "To load data into a Pandas Dataframe, you can use the `pandas.read_*` suite of functions. Common examples are.\n",
    "- `pandas.read_csv()` to read from a comma separated values file\n",
    "- `pandas.read_sql()` to read directly from a SQL database (either table by name or SQL query constructed as a string)\n",
    "- `pandas.read_table()` to read from a more general delimited tabular file (could be comma, tab, space, `'|'`, or otherwise delimited)\n",
    "- `pandas.read_json()` to read from a .json file, but pandas will expect the JSON data to have a particular structure\n",
    "- `pandas.read_parquet()` to read from an Apache Parquet columnar store file\n",
    "\n",
    "Below, we define a function that uses `pandas.read_parquet()` to load the Synthea data from parquet files\n",
    "\n",
    "Data for 1,000 synthetic patients, divided into four states, was generated using the [Synthea tool](https://synthea.mitre.org/)\n",
    "This data is split into four separate directories\n",
    "```\n",
    "output_hi/ # patients in Hawaii\n",
    "output_ma/ # patients in Massacusetts\n",
    "output_tx/ # patients in Texas\n",
    "output_wa/ # patients in Washington\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a723262c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper function for loading data from the Github repository\n",
    "def load_data_from_github(filename):\n",
    "    url = os.path.join('https://github.com/expmed/arch_workshop_core_python_skills_ws13/raw/refs/heads/main/data', filename)\n",
    "    return pd.read_parquet(url) # uses pandas.read_parquet() to read the parquet() formatted data from the repository"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81d4137f",
   "metadata": {},
   "source": [
    "### Skill Introduction - Concatenation of DataFrames\n",
    "- If we want to work with a single dataset of all patients in a single DataFrame, we can use the built-in `pandas.concat()` function\n",
    "- `pandas.concat()` can take in a bracketed list of dataframes, such as `[df1, df2, df3,...]` and concatenate them together row-wise into a single table\n",
    "- The only requirement (or recommendation) is that all dataframes to be appended in this way have the same schema (names, types, and number of columns)\n",
    "- Since the data for the four simulated states is split into separate files, we use `pd.concat()` to stitch together the data into individual DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c89d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first load in the patients files for the four states\n",
    "patients_hi = load_data_from_github('output_hi_small/parquet/patients.parquet')\n",
    "patients_ma = load_data_from_github('output_ma_small/parquet/patients.parquet')\n",
    "patients_tx = load_data_from_github('output_tx_small/parquet/patients.parquet')\n",
    "patients_wa = load_data_from_github('output_wa_small/parquet/patients.parquet')\n",
    "\n",
    "# place all patients dataframes in a list\n",
    "patients_dfs = [patients_hi, patients_ma, patients_tx, patients_wa]\n",
    "# concatenate them\n",
    "patients = pd.concat([patients_hi, patients_ma, patients_tx, patients_wa])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b66571",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirming that the consolidated patients dataframe has the same number of rows as all four dataframes\n",
    "assert(len(patients) == sum([len(df) for df in patients_dfs]))\n",
    "# confirming that the consolidated dataframe has the same columns as the individual ones\n",
    "assert(len(patients.columns) == len(patients_hi.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a2cbd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now define an additional helper function to simplify loading and concatenating data for the other files\n",
    "def load_consolidated_data_for_file(filename):\n",
    "    print(f\"Loading data for {filename}\")\n",
    "    # uses a list comprehension to load the data for each of the four states into a list\n",
    "    df = pd.concat([ # use pd.concat to append/concatenate the data for all states together into a single frame\n",
    "        load_data_from_github(f\"{output_dir}/parquet/{filename}\") # use read_csv to load the data from each output directory\n",
    "        for output_dir in tqdm(['output_hi_small', 'output_ma_small', 'output_tx_small', 'output_wa_small']) # loop over each output directory\n",
    "    ])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ea975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in the conditions, observations, and medications files\n",
    "conditions = load_consolidated_data_for_file('conditions.parquet')\n",
    "observations = load_consolidated_data_for_file('observations.parquet')\n",
    "medications = load_consolidated_data_for_file('medications.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf766787",
   "metadata": {},
   "source": [
    "### Skill Introduction - Inspecting DataFrames\n",
    "If we want to see a summary of the contents of a DataFrame, we can use the following methods and properties\n",
    "1. We can use `df.head(n)` to display the first `n` rows of a DataFrame\n",
    "2. We can access the `.columns` property of a DataFrame to display the names of all of the columns\n",
    "3. We can access the `.dtypes` property of a DataFrame to show the columns and their datatypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a26a8f5f-fc93-4b18-b7c2-0bb1a53c6958",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first 5 rows\n",
    "conditions.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa39f7d3-2318-4714-a2bf-2e59cd889d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the columns in the DataFrame\n",
    "conditions.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10182c76-37ae-4fbf-8759-577883140523",
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the columns and their datatypes\n",
    "conditions.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9fe1c95",
   "metadata": {},
   "source": [
    "## I.b Selecting Patients with Type 2 Diabetes\n",
    "\n",
    "For this mock investigation, we are interested in patients who have been diagnosed with Type 2 Diabetes \\\n",
    "In order to extract the patients with Type 2 diabetes, we can use the `conditions` table, which stores \\\n",
    "[SNOMED CT](https://www.snomed.org/what-is-snomed-ct) coded diagnoses of various conditions, including Type 2 diabetes. \\\n",
    "While we can easily google/look up the SNOMED CT code for type 2 diabetes and use that to filter our `conditions` \\\n",
    "for instructive purposes, we will learn how to use Pandas search through the data to find which code we should use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9d7f314",
   "metadata": {},
   "source": [
    "### Skill Introduction - Searching and Filtering Through DataFrames\n",
    "- If we want to see the values that a particular column/`Series` in a DataFrame has, we can index into the dataframe with `df[<column_name>]`\n",
    "- If we want to see all of the possible values that a column takes along with the number of records containing each value, we can use `df[<column_name>].value_counts()`\n",
    "- If we want to search a text-based/`string`/`object` type column, we can use the `df[<column_name>].str.contains(<pattern>, ...)` method\n",
    "- If we want to filter a DataFrame to only include specific values for a column, we can use boolean indexing such as `df[df[<column_name>] == value]`\n",
    "- If we want to count the number of unique values present in a column, we can use `df[<column_name>].nunique()`\n",
    "Below, we use all three of these to hone in on the patients with Type 2 Diabetes diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc571f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we index into the DESCRIPTION column to see its contents\n",
    "conditions['DESCRIPTION']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbcc529d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we use value counts to see a frequency breakdown of the various condition descriptions\n",
    "conditions['DESCRIPTION'].value_counts().head(20) # we also use head(20) to show the top 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5269cb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we use the .str.contains() method to find conditions with the substring \"diabetes\" in the description\n",
    "diabetes_related_conditions = conditions[\n",
    "    conditions['DESCRIPTION'].str.contains('diabetes', case=False) # uses case=False to make it case-insensitive search\n",
    "]\n",
    "diabetes_related_conditions['DESCRIPTION'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bdf71e9",
   "metadata": {},
   "source": [
    "We notice from the above summary that there are patients diagnosed explicitly with `Diabetes mellitus type 2 (disorder)`, and there are also numerous patients diagnosed with co-morbidities described as being \"due to\" type 2 diabetes mellitus. In order to ensure that we capture all patients with Type 2 diabetes, we use additional substring filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e591238",
   "metadata": {},
   "outputs": [],
   "source": [
    "type2_diabetes = conditions[\n",
    "    conditions['DESCRIPTION'].str.contains('type 2', case=False) & # Uses the '&' operation to take the conjunction of the two boolean indices\n",
    "    conditions['DESCRIPTION'].str.contains('diabetes', case=False)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d0f3237",
   "metadata": {},
   "outputs": [],
   "source": [
    "type2_diabetes['DESCRIPTION'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae77eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next we count the unique patients with Type 2 diabetes\n",
    "type2_diabetes['PATIENT'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08678ecd",
   "metadata": {},
   "source": [
    "## I.c) Analysis of Hemoglobin A1c (HbA1c) Labs in Type 2 and Non-Type 2 patients\n",
    "Now we will analyze Hemoglobin A1C levels for patients with and without a type 2 diabetes diagnosis \\\n",
    "To do this, we first filter the observations table for all hemoglobin A1C lab results \\\n",
    "We can use [LOINC](https://en.wikipedia.org/wiki/LOINC) code: `4548-4`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df7b7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemoglobin_a1c = observations[observations['CODE'] == '4548-4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f65c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemoglobin_a1c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed558fc6",
   "metadata": {},
   "source": [
    "### Skill Introduction - Assigning new Variables to a DataFrame\n",
    "- To assign a new variable to a dataframe, we can call the `df.assign()` method which returns a new copy of the dataframe with the added variable(s)\n",
    "- You can also assign directly to a newly named variable by indexing it, such as `df['variable'] = value(s)`, but this directly mutates the DataFrame\n",
    "Next, we add another variable/column to the `hemoglobin_a1c` data to label patients with/without a Type2 diabetes diagnosis. \\ Below, we demonstrate a DataFrame variable creation wherein we performing multiple operations at once\n",
    "\n",
    "1. The outermost operation is a call to `hemoglobin_a1c.assign()` to assign a new variable/column to the dataframe of HbA1c labs\n",
    "2. To the new variable `HASDIABETES`, we are assigning a series\n",
    "3. The series we are assigning is a boolean series created by calling the `.isin()` method, effectively asking if the `PATIENT` ID of the record is in the set of IDs in the type 2 diabetes diagnoses\n",
    "4. On this boolean series (which by default has values `True` and `False`) we are transforming the values into integers (1 for True, 0 for False) using `.astype('int')` to convert to integers\n",
    "\n",
    "*NOTE:* We are cheating/simplifying somewhat. Really what we probably should do is label the HbA1c labs based on whether they occured before/after the diagnosis of Type 2 diabetes (within a certain time delta) to perhaps get a more accurate labeling of the labs. However, this would require creating an auxiliary data structure and lead to more complicated code, so we use this simpler approach for sake of brevity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b9ed47",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemoglobin_a1c_labeled = hemoglobin_a1c.assign( # calling .assign() to assign a new variable/column to the dataframe\n",
    "    HASDIABETES=hemoglobin_a1c['PATIENT'].isin(type2_diabetes['PATIENT']).astype('int') # creating a new column named 'HASDIABETES'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98830c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemoglobin_a1c_labeled['HASDIABETES'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d0e4b37",
   "metadata": {},
   "source": [
    "### Skill Introduction - Visualization of Data Distributions with Seaborn\n",
    "The seaborn package can be used to visualize the distribution of continuous and categorical variables in data through a suite of built in plots\n",
    "- `seaborn.kdeplot()` can be used to visualize a histogram with a curve fit to it via Kernel Density Estimation (KDE) to summarize a distribution\n",
    "- `seaborn.violinplot()` can also be used to visualize the distribution of data, showing both density and summary stats like median and IQR\n",
    "- We can also use the Pandas method `df[<column_name>].describe()` to produce summary stats for the data in a particular column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0346c0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot a Kernel Density Estimate of the distrubtion (probability density function) of Hemoglobin A1C lab measurements for Type 2 and Non Type 2 Patients\n",
    "sns.kdeplot(\n",
    "    hemoglobin_a1c_labeled.query('HASDIABETES == 1')['VALUE'].astype('float'), # Plotting the lab result VALUE for patients with Type 2\n",
    "    label=\"With Diabetes\", color=\"red\", alpha=0.4, common_norm=False # plotting as a red curve with an appropriate label\n",
    ")\n",
    "sns.kdeplot(\n",
    "    hemoglobin_a1c_labeled.query('HASDIABETES == 0')['VALUE'].astype('float'),  # Plotting the data for the patients without Type 2 diabetes\n",
    "    label=\"Without Diabetes\", color=\"blue\", alpha=0.4, common_norm=False # plotting as a blue curve\n",
    ")\n",
    "# add a legend\n",
    "plt.legend()\n",
    "# change label of the xaxis\n",
    "plt.xlabel('HbA1C (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec227a07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# use seaborn to create a violin plot of the two distributions\n",
    "sns.violinplot(\n",
    "    hemoglobin_a1c_labeled.astype({'VALUE': float}),\n",
    "    x='HASDIABETES',\n",
    "    y='VALUE'\n",
    ")\n",
    "# change the label of the y-axis\n",
    "plt.ylabel('HbA1C (%)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac80878",
   "metadata": {},
   "outputs": [],
   "source": [
    "hemoglobin_a1c_labeled.astype({'VALUE': 'float'}).groupby('HASDIABETES')['VALUE'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7159c326",
   "metadata": {},
   "source": [
    "The U.S. CDC has the following reference values published for Hemoglobin A1C\n",
    "\n",
    "Normal: below 5.7% \\\n",
    "Prediabetes: 5.7% to 6.4% \\\n",
    "Diabetes: 6.5% or above \n",
    "\n",
    "In looking at the distribution plots above, we see that patients without a Type 2 diabetes diagnosis have an A1c distribution that is roubhly bi-modal, with one mode below 4.0% and another within the Pre-diabetes range of 5.7% to 6.4%\n",
    "\n",
    "We also see that the patients with Type 2 diabetes diagnosis have a multi-modal HbA1c distribution, and a long tail that extends as high as to roughly 12%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a235f4",
   "metadata": {},
   "source": [
    "### Skill Introduction - Statistical Testing with Scipy\n",
    "If we want to quantify whether there is a significant difference in the two distributions \\\n",
    "one option is the use the Mann-Whitney U (Wilcoxon rank-sum) test \\\n",
    "provided by scipy's `mannwhitneyu()` function.\n",
    "\n",
    "Another test we can perform is the Kolmogorov Smirnov test to test for subtle differences in shape of the two distributions.\n",
    "We can perform a two-sample KS test using Scipy's `ks_2samp()` function.\n",
    "\n",
    "The Mann-Whitney U test is mostly sensitive to changes in the median.\n",
    "The KS test is sensitive to any differences in the two distributions (shape, spread, or median)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52203f2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "U1, p = sp.stats.mannwhitneyu(\n",
    "    hemoglobin_a1c_labeled.query('HASDIABETES == 1')['VALUE'].astype('float'),\n",
    "    hemoglobin_a1c_labeled.query('HASDIABETES == 0')['VALUE'].astype('float'), \n",
    "    method=\"auto\"\n",
    ")\n",
    "print(f\"U1: {U1}, p-value: {p}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f2923c",
   "metadata": {},
   "outputs": [],
   "source": [
    "statistic, p_value = sp.stats.ks_2samp(\n",
    "    hemoglobin_a1c_labeled.query('HASDIABETES == 1')['VALUE'].astype('float'),\n",
    "    hemoglobin_a1c_labeled.query('HASDIABETES == 0')['VALUE'].astype('float')\n",
    ")\n",
    "print(f\"KS Statistic: {statistic}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e34634bf",
   "metadata": {},
   "source": [
    "# Discussion Points\n",
    "1. Why is it that we observe a (roughly) bi-modal distribution in A1C values among patients without a Type 2 Diabetes diagnosis?\n",
    "2. Why do we observe right skewness and high A1C outliers in diabetic patients, while observing a median A1C value and prominent mode that is well within the defined normal range?\n",
    "3. How can we extend this analysis to add additional nuance (additional lab tests, adding data from other tables, partitioning patients further based on \\\n",
    "   other diagnoses, medications, demographics etc)?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f718b36f",
   "metadata": {},
   "source": [
    "# II. Open Ended Exploration & Extensions to Initial Analysis\n",
    "Try to see if you can extend the initial analysis that we did on Hemoglobin A1C and diabetes\n",
    "\n",
    "1. Are there any other labs that you could pull data for and compare distributions for between Type-2 and non-Type2 patients\n",
    "2. Could you further subdivide the Type 2 and non-Type 2 patients into additional subsets based on other diagnoses/demographics/medication status?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44efa95e",
   "metadata": {},
   "source": [
    "**Click Below for Hints**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a46c5db",
   "metadata": {},
   "source": [
    "<details>\n",
    "    <summary>Hint 1</summary>\n",
    "    <p>The medications table has both a <code>'REASONCODE'</code> abd <code>'REASONDESCRIPTION'</code> column which describe why the medication was prescribed</p>\n",
    "</details>\n",
    "<details>\n",
    "    <summary>Hint 2</summary>\n",
    "    <p>If you aren't sure which LOINC to query for a particular lab for, you can always use the <code>Series.str.contains('_PATTERN_', case=False)</code> technique to perform a string search</p>\n",
    "</details>\n",
    "<details>\n",
    "    <summary>Hint 3</summary>\n",
    "    <p>If you want to search for the SNOMED CT code for other diagnoses, such as Pre-diabetes, you can do that via <a href=\"https://browser.ihtsdotools.org/?perspective=full&conceptId1=9414007&edition=MAIN/2025-06-01&release=&languages=en\">SNOMED Browser</a></p>\n",
    "    <p> You can also take advantage of string/keyword search, again via <code>Series.str.contains('_PATTERN_', case=False)</code></p>\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b1f61e2",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
